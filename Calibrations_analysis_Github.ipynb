{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "os.chdir('C:\\\\Users\\\\VanBuren\\\\Desktop\\\\Coursework\\\\Capstone\\\\Coding_analysis\\\\Test_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5328656567210689\n"
     ]
    }
   ],
   "source": [
    "#NYDEC CALIBRATION SCHEME\n",
    "#----USEFUL FOR NON-SUBWAY CALIBRATIONS: INDOOR/OUTDOOR TIME.\n",
    "#designate timespan we want\n",
    "start = dt.datetime.strptime('2020-07-10', '%Y-%m-%d')\n",
    "end = dt.datetime.strptime('2021-01-27', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Function to remove timezone awareness from utc datetime fields (for easier manipulation),\n",
    "#     and to trim data to start and end timestamps:\n",
    "def utc_delocalize(frame, field, start, end):\n",
    "    frame[field] = pd.to_datetime(frame[field]).dt.tz_localize(None)\n",
    "    frame = frame.loc[(frame[field] >= start) & ((frame[field] < end))]\n",
    "    frame = frame.set_index(frame[field])\n",
    "    return frame\n",
    "\n",
    "\n",
    "#Read in the NY DEC data, combine date/time columns into one datetime field for easier analysis\n",
    "refdata = pd.read_csv('nydec.csv',header = 1,parse_dates=[['Date','Time']])\n",
    "refdata = refdata.rename(columns={\"PM25C_ug/m3LC\":\"PM2.5_ref\"})\n",
    "\n",
    "\n",
    "# Localize refdata to UTC (then remove timezone awareness)\n",
    "#     refdata's datetime field was captured in Eastern time, but the field is not timezone-aware.\n",
    "#         First set timezone awareness, then convert to UTC:\n",
    "refdata['Date_Time'] = refdata['Date_Time'].dt.tz_localize('US/Eastern', ambiguous = 'NaT')\n",
    "refdata['Date_Time'] = refdata['Date_Time'].dt.tz_convert('UTC')\n",
    "refdata = utc_delocalize(refdata, 'Date_Time', start, end)\n",
    "\n",
    "\n",
    "# read in purpleair datasets: hour averages (for best comparison to refdata data)\n",
    "#     then limit range of PA sensor data to desired timespan\n",
    "#     then set index to timestamp\n",
    "sensA = pd.read_csv('school_4_A_hr.csv',header = 0)\n",
    "sensA = sensA.rename(columns={\"Temperature_F\":\"Temp\",\"PM2.5_ATM_ug/m3\":\"PM2.5A\"})\n",
    "sensA = utc_delocalize(sensA, 'created_at', start, end)\n",
    "\n",
    "\n",
    "sensB = pd.read_csv('school_4_B_hr.csv',header = 0)\n",
    "sensB = sensB.rename(columns={\"PM2.5_ATM_ug/m3\":\"PM2.5B\"})\n",
    "sensB = utc_delocalize(sensB, 'created_at', start, end)\n",
    "\n",
    "\n",
    "#Get all info onto a single dataframe\n",
    "df = pd.concat([sensA[['Temp','Humidity_%','PM2.5A']], sensB['PM2.5B'], refdata['PM2.5_ref']], axis = 1)\n",
    "df['PM2.5_test'] = df[['PM2.5A','PM2.5B']].mean(axis = 1)\n",
    "\n",
    "\n",
    "#Null values will cause problems in statswork later on, so eliminate them now.\n",
    "df_nulls = ['PM2.5_ref', 'PM2.5_test', 'Temp', 'Humidity_%']\n",
    "\n",
    "def null_remover(frame, fields):\n",
    "    for field in fields:\n",
    "        frame = frame.loc[frame[field].notnull()]\n",
    "    return frame\n",
    "\n",
    "df = null_remover(df, df_nulls)\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#statswork for multiple regression\n",
    "#Parameters for regression in X, assume they're predictors for nydec data as y\n",
    "\n",
    "#trained model: nydec = x0 + x1[temp] + x2[humidity] + x3[PA data]\n",
    "\n",
    "X = np.array(df[['Temp','Humidity_%','PM2.5_test']])\n",
    "y = np.array(df['PM2.5_ref'])\n",
    "reg = lr(fit_intercept = False).fit(X,y)\n",
    "\n",
    "#-------------------------------------------\n",
    "# CALIBRATION FUNCTION FOR OUTDOOR/INDOOR (NON-TRAIN/PLATFORM) DATA\n",
    "def reg_out(X):\n",
    "    return np.dot(X,reg.coef_)\n",
    "#-------------------------------------------\n",
    "\n",
    "#R-square:\n",
    "print(reg.score(X,y))\n",
    "\n",
    "#run that model on the parameters\n",
    "df['PM2.5_calib'] = np.dot(X,reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALIBRATION SCHEME B\n",
    "#Luglio curve--meant for on the train platforms\n",
    "\n",
    "# Based on mass calculations from air filter collections\n",
    "filt = pd.read_csv('Gravcal.csv', header = 0)\n",
    "\n",
    "\n",
    "X = np.column_stack([np.zeros(len(filt['PA PM2.5 avg'])),filt['PA PM2.5 avg']])\n",
    "y = np.array(filt['Grav(average)'])\n",
    "calibs = lr(fit_intercept = False).fit(X,y)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CALIBRATION FOR UNDERGROUND PLATFORM & TRAIN DATA\n",
    "def reg_plat(X):\n",
    "    return calibs.coef_[1] * X\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Scheme C\n",
    "# For dealing with PA and aboveground trains:\n",
    "#!!! AND HERE, GET RID OF THE LAMBDA\n",
    "reg_sir = lambda q: q*(30.9/36.2)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CALIBRATION FOR ABOVEGROUND PLATFORMS AND TRAINS\n",
    "def reg_sir(X):\n",
    "    return X * (30.9/36.2)\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive calibration function to calibrate datasets according to location code\n",
    "\n",
    "def calibrate(frame):\n",
    "    \n",
    "    #Establish which code gets calibrated how\n",
    "    codes_nydec = ['O','I','F']\n",
    "    codes_luglio = ['PU','T','E']\n",
    "    codes_sir = ['PA']\n",
    "    \n",
    "    \n",
    "    #then calibrate based on Loc_code:\n",
    "    frame['PM2.5_calib'] = np.nan\n",
    "    \n",
    "    #nydec calibration\n",
    "    X_nydec = frame[['Temp','Humidity_%','PM2.5']].loc[frame['Loc_code'].isin(codes_nydec)]\n",
    "    frame['PM2.5_calib'].loc[frame['Loc_code'].isin(codes_nydec)] = reg_out(X_nydec)\n",
    "    \n",
    "    #luglio calibration\n",
    "    X_luglio = frame['PM2.5'].loc[frame['Loc_code'].isin(codes_luglio)]\n",
    "    frame['PM2.5_calib'].loc[frame['Loc_code'].isin(codes_luglio)] = reg_plat(X_luglio)\n",
    "    \n",
    "    #SIR calibration for aboveground plats\n",
    "    X_sir = frame['PM2.5'].loc[frame['Loc_code'].isin(codes_sir)]\n",
    "    frame['PM2.5_calib'].loc[frame['Loc_code'].isin(codes_sir)] = reg_sir(X_sir)\n",
    "    \n",
    "    #Special aboveground train calibration using SIR\n",
    "    X_sir2 = frame['PM2.5'].loc[(frame['Loc_code']=='T') & (frame['Outside? (Y/N)'] == 'Y')]\n",
    "    frame['PM2.5_calib'].loc[(frame['Loc_code']=='T') & (frame['Outside? (Y/N)'] == 'Y')] = reg_sir(X_sir2)\n",
    "    \n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VanBuren\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Keeping the other imports below for posterity and/or potential emergencies? idk, just don't wanna delete yet\n",
    "dfsub = pd.read_csv('Master_compiled_BB.csv',header = 0, parse_dates = [['Date', 'Time_NYC']]).rename(\n",
    "    columns = {'Temperature (F)': 'Temp','Humidity (%)':'Humidity_%','PA PM2.5 (um/m3)':'PM2.5'})\n",
    "\n",
    "dfsub = dfsub.loc[dfsub['PM2.5'].notnull() & dfsub['Temp'].notnull() & dfsub['Humidity_%'].notnull() & \n",
    "                  dfsub['Location'].notnull()]\n",
    "dfsub = calibrate(dfsub)\n",
    "# dfsub.loc[(dfsub['Loc_code']=='T') & (dfsub['Outside? (Y/N)'] == 'Y')]\n",
    "dfsub.to_csv('Masterlist.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
